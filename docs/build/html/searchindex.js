Search.setIndex({"docnames": ["README", "autograd", "autograd.core", "autograd.torch", "autograd.torch.nn", "autograd.torch.optim", "faq", "index", "modules", "setup", "test"], "filenames": ["README.rst", "autograd.rst", "autograd.core.rst", "autograd.torch.rst", "autograd.torch.nn.rst", "autograd.torch.optim.rst", "faq.rst", "index.rst", "modules.rst", "setup.rst", "test.rst"], "titles": ["Get started", "autograd package", "autograd.core package", "autograd.torch package", "autograd.torch.nn package", "autograd.torch.optim package", "FAQ", "Welcome to Nano-AutoGrad's Documentation!", "Nano-AutoGrad", "setup module", "test package"], "terms": {"i": [0, 4, 7, 10], "micro": 0, "framework": [0, 6, 7], "enabl": 0, "build": 0, "train": [0, 6], "neural": [0, 4, 6, 7], "network": [0, 4, 6, 7], "from": [0, 2, 3, 10], "scratch": 0, "base": [0, 2, 3, 4, 5, 6, 7], "an": [0, 4, 6, 7], "autodifferenti": 0, "auto": 0, "diff": 0, "engin": [0, 1, 8, 10], "comput": [0, 2, 3, 4, 6, 7, 10], "graph": [0, 1, 3, 8, 10], "It": [0, 6, 7], "implement": [0, 4, 5, 10], "backpropag": [0, 2, 3], "revers": [0, 6], "mode": [0, 6], "autodiff": 0, "over": [0, 4], "dynam": 0, "built": 0, "direct": 0, "acycl": 0, "dag": 0, "The": [0, 2, 3, 4, 5, 6, 7, 10], "also": 0, "includ": [0, 6], "small": [0, 6], "librari": [0, 7], "top": 0, "provid": [0, 6, 7], "pytorch": [0, 7, 10], "like": [0, 7], "api": [0, 6], "both": [0, 6, 10], "compon": 0, "ar": [0, 3, 7, 10], "compact": 0, "approxim": 0, "100": 0, "line": 0, "code": [0, 6, 7], "50": 0, "design": [0, 6], "lightweight": [0, 6, 7], "potenti": 0, "us": [0, 2, 3, 5, 7, 10], "educ": 0, "purpos": 0, "To": [0, 6], "you": [0, 6, 7], "can": [0, 7], "pip": [0, 6], "autogead": [0, 6], "core": [0, 1, 8, 10], "abil": [0, 6], "here": [0, 6], "two": [0, 3], "creat": [0, 10], "class": [0, 2, 3, 4, 5, 7], "repres": [0, 2, 3], "nn": [0, 1, 3, 8], "import": 0, "modul": [0, 7, 8], "def": 0, "__init__": 0, "self": 0, "nin": [0, 2], "nout": [0, 2], "initi": 0, "arg": [0, 2, 3, 4], "number": 0, "input": [0, 4], "featur": [0, 7], "A": [0, 2, 3], "list": [0, 2], "output": [0, 2], "each": [0, 3], "sz": 0, "1": [0, 3, 4, 5], "nonlin": [0, 2], "len": 0, "rang": 0, "__call__": 0, "x": [0, 4], "valu": [0, 1, 2, 4, 10], "return": [0, 2, 3, 4, 5], "paramet": [0, 1, 2, 3, 4, 5], "all": [0, 2, 3, 4, 5, 7], "p": 0, "__repr__": 0, "string": 0, "represent": 0, "f": 0, "join": 0, "str": 0, "spars": [0, 2], "spares_nn": [0, 1, 8], "sparselay": [0, 1, 2], "sparsiti": [0, 2], "level": 0, "dense_grad": 0, "fals": [0, 2, 3], "boolean": 0, "indic": 0, "whether": [0, 2], "gradient": [0, 2, 3, 5, 6, 7, 10], "weight": 0, "dens": 0, "lieanr": 0, "torch": [0, 1, 8], "tensor": [0, 1, 4, 8, 10], "optim": [0, 1, 3, 6, 7], "sgd": [0, 3, 5], "functiona": 0, "super": 0, "l1": 0, "784": 0, "1568": 0, "name": [0, 2, 3, 4], "l2": 0, "392": 0, "l3": 0, "10": 0, "forward": [0, 3, 4, 6, 10], "z": 0, "relu": [0, 1, 2, 3, 4], "out": [0, 6], "log_softmax": [0, 1, 3, 4], "lr": [0, 5], "5e": 0, "2": 0, "weight_decai": [0, 5], "1e": 0, "4": 0, "schedul": 0, "lr_schedul": [0, 1, 3], "linearlr": [0, 3, 5], "start_factor": [0, 5], "0": [0, 2, 4, 5], "end_factor": [0, 5], "75": 0, "total_it": [0, 5], "num_epoch": 0, "visit": 0, "repo": 0, "github": [0, 6], "submodul": [1, 7, 8], "draw_dot": [1, 2], "trace": [1, 2], "zero_grad": [1, 2, 3, 5], "sparsemlp": [1, 2], "sparseneuron": [1, 2], "backward": [1, 2, 3, 10], "softmax": [1, 2, 3, 4], "layer": [1, 2, 4], "mlp": [1, 2], "neuron": [1, 2], "function": [1, 2, 3, 7], "init": [1, 8], "node": [1, 2, 3], "t": [1, 3, 4, 6], "accum_grad": [1, 3], "broadcast_axi": [1, 3], "exp": [1, 3, 4], "grad_en": [1, 3], "log": [1, 3, 4], "sigmoid": [1, 3, 4], "sum": [1, 3], "tanh": [1, 3, 4], "no_grad": [1, 3], "root": 2, "graph_nam": 2, "draw": 2, "graphviz": 2, "object": [2, 3, 4, 5, 10], "start": [2, 3, 7], "point": 2, "filenam": 2, "digraph": 2, "tupl": [2, 3], "contain": 2, "set": [2, 5, 6, 7], "edg": 2, "zero": [2, 5], "kwarg": [2, 4], "true": [2, 3], "data": [2, 3], "none": [2, 3], "_children": 2, "_op": 2, "label": 2, "store": [2, 3], "singl": [2, 5], "scalar": 2, "its": [2, 4, 6, 7], "keep_graph": 2, "perform": [2, 3, 4, 5, 6, 7, 10], "keep": 2, "higher": 2, "order": 2, "appli": [2, 3, 4], "rectifi": [2, 3, 4], "linear": [2, 3, 4, 6, 7], "unit": [2, 3], "activ": [2, 3, 4], "new": [2, 6], "binary_cross_entropi": [3, 4], "huber_loss": [3, 4], "mse_loss": [3, 4], "nll_loss": [3, 4], "lrschedul": [3, 5], "get_lr": [3, 5], "step": [3, 5, 6, 7], "grad_fn": 3, "next_funct": 3, "requires_grad": 3, "properti": 3, "transpos": 3, "grad": 3, "accumul": 3, "retain_graph": 3, "involv": 3, "leaf": 3, "requir": 3, "thi": [3, 4, 5, 7, 10], "method": [3, 4, 5], "travers": 3, "associ": 3, "current": [3, 5, 6], "propag": 3, "previou": 3, "respect": 3, "w": [3, 4], "r": 3, "retain": 3, "If": [3, 4, 6, 10], "otherwis": 3, "freed": 3, "default": 3, "static": 3, "shape_left": 3, "shape_right": 3, "determin": 3, "ax": 3, "along": [3, 4], "which": [3, 4], "broadcast": 3, "occur": 3, "between": [3, 4], "shape": 3, "left": 3, "right": 3, "exponenti": [3, 4], "element": [3, 4], "result": [3, 4], "natur": [3, 4], "logarithm": [3, 4], "dim": [3, 4], "follow": [3, 6], "dimens": [3, 4], "after": 3, "wise": [3, 4], "keepdim": 3, "reduc": 3, "option": 3, "size": [3, 6], "hyperbol": [3, 4], "tangent": [3, 4], "interfac": 4, "target": 4, "binari": 4, "cross": 4, "entropi": 4, "loss": [4, 10], "delta": 4, "huber": 4, "threshold": 4, "absolut": 4, "error": 4, "specifi": [4, 10], "mean": 4, "squar": 4, "mse": 4, "neg": 4, "likelihood": 4, "in_featur": 4, "out_featur": 4, "transform": 4, "y": 4, "b": 4, "inp": 4, "pass": [4, 10], "through": [4, 7], "need": 4, "subclass": [4, 5], "defin": [4, 6], "actual": 4, "take": 4, "place": 4, "dure": 4, "rais": [4, 6, 10], "notimplementederror": 4, "iter": 4, "sub": 4, "last_epoch": 5, "calcul": 5, "learn": [5, 6, 7], "rate": 5, "should": 5, "updat": 5, "epoch": 5, "we": 6, "answer": 6, "common": [6, 7], "question": 6, "troubleshoot": [6, 7], "tip": [6, 7], "best": [6, 7], "practic": [6, 7], "relat": 6, "effect": [6, 7], "python": [6, 7], "automat": [6, 7], "differenti": [6, 7], "simpl": [6, 7], "effici": [6, 7], "wai": [6, 7], "machin": [6, 7], "task": [6, 7], "offer": 6, "kei": 6, "support": 6, "integr": 6, "numpi": 6, "seamless": 6, "arrai": 6, "oper": [6, 10], "easi": 6, "custom": 6, "run": 6, "command": 6, "refer": 6, "usag": 6, "section": [6, 7], "document": 6, "instruct": [6, 7], "up": [6, 7], "your": [6, 7], "project": [6, 7], "independ": 6, "howev": 6, "combin": 6, "leverag": 6, "them": 6, "complex": 6, "model": [6, 10], "rel": 6, "mai": 6, "have": 6, "some": 6, "doesn": 6, "gpu": 6, "acceler": 6, "distribut": 6, "primarili": 6, "focus": 6, "solut": 6, "medium": 6, "problem": 6, "variou": [6, 7], "demonstr": [6, 7], "differ": [6, 7, 10], "regress": [6, 7], "addition": 6, "explor": [6, 7], "offici": 6, "repositori": 6, "tutori": 6, "commun": 6, "contribut": 6, "addit": [6, 10], "pleas": 6, "feel": 6, "free": 6, "reach": 6, "our": 6, "forum": 6, "aim": 7, "depth": 7, "understand": 7, "get": 7, "packag": [7, 8], "setup": [7, 8], "test": [7, 8], "subpackag": [7, 8], "test_engin": [7, 8], "q": 7, "what": 7, "main": 7, "how": 7, "do": 7, "other": 7, "tensorflow": 7, "ani": 7, "limit": 7, "known": 7, "issu": 7, "where": 7, "find": 7, "more": 7, "resourc": 7, "depend": 7, "guid": 7, "case": 7, "workflow": 7, "detail": 7, "avail": 7, "serv": 7, "comprehens": 7, "help": 7, "util": 7, "capabl": 7, "showcas": 7, "illustr": 7, "address": 7, "index": 7, "term": 7, "keyword": 7, "search": 7, "page": 7, "specif": 7, "inform": 7, "within": 7, "content": 8, "test_model": [8, 10], "test_more_op": [8, 10], "test_sanity_check": [8, 10], "tinytorch": 10, "against": 10, "correspond": 10, "compar": 10, "obtain": 10, "assert": 10, "close": 10, "assertionerror": 10, "beyond": 10, "toler": 10, "same": 10, "replic": 10, "equal": 10, "saniti": 10, "check": 10}, "objects": {"": [[1, 0, 0, "-", "autograd"], [10, 0, 0, "-", "test"]], "autograd": [[2, 0, 0, "-", "core"], [3, 0, 0, "-", "torch"]], "autograd.core": [[2, 0, 0, "-", "Graph"], [2, 0, 0, "-", "Spares_nn"], [2, 0, 0, "-", "engine"], [2, 0, 0, "-", "nn"]], "autograd.core.Graph": [[2, 1, 1, "", "draw_dot"], [2, 1, 1, "", "trace"]], "autograd.core.Spares_nn": [[2, 2, 1, "", "Module"], [2, 2, 1, "", "SparseLayer"], [2, 2, 1, "", "SparseMLP"], [2, 2, 1, "", "SparseNeuron"]], "autograd.core.Spares_nn.Module": [[2, 3, 1, "", "parameters"], [2, 3, 1, "", "zero_grad"]], "autograd.core.Spares_nn.SparseLayer": [[2, 3, 1, "", "parameters"]], "autograd.core.Spares_nn.SparseMLP": [[2, 3, 1, "", "parameters"]], "autograd.core.Spares_nn.SparseNeuron": [[2, 3, 1, "", "parameters"]], "autograd.core.engine": [[2, 2, 1, "", "Value"]], "autograd.core.engine.Value": [[2, 3, 1, "", "backward"], [2, 3, 1, "", "relu"], [2, 3, 1, "", "softmax"]], "autograd.core.nn": [[2, 2, 1, "", "Layer"], [2, 2, 1, "", "MLP"], [2, 2, 1, "", "Module"], [2, 2, 1, "", "Neuron"]], "autograd.core.nn.Layer": [[2, 3, 1, "", "parameters"]], "autograd.core.nn.MLP": [[2, 3, 1, "", "parameters"]], "autograd.core.nn.Module": [[2, 3, 1, "", "parameters"], [2, 3, 1, "", "zero_grad"]], "autograd.core.nn.Neuron": [[2, 3, 1, "", "parameters"]], "autograd.torch": [[3, 0, 0, "-", "init"], [4, 0, 0, "-", "nn"], [5, 0, 0, "-", "optim"], [3, 0, 0, "-", "tensor"]], "autograd.torch.nn": [[4, 0, 0, "-", "functional"], [4, 0, 0, "-", "module"]], "autograd.torch.nn.functional": [[4, 1, 1, "", "binary_cross_entropy"], [4, 1, 1, "", "exp"], [4, 1, 1, "", "huber_loss"], [4, 1, 1, "", "log"], [4, 1, 1, "", "log_softmax"], [4, 1, 1, "", "mse_loss"], [4, 1, 1, "", "nll_loss"], [4, 1, 1, "", "relu"], [4, 1, 1, "", "sigmoid"], [4, 1, 1, "", "tanh"]], "autograd.torch.nn.module": [[4, 2, 1, "", "Linear"], [4, 2, 1, "", "Module"]], "autograd.torch.nn.module.Linear": [[4, 3, 1, "", "forward"]], "autograd.torch.nn.module.Module": [[4, 3, 1, "", "forward"], [4, 3, 1, "", "modules"], [4, 3, 1, "", "parameters"]], "autograd.torch.optim": [[5, 0, 0, "-", "lr_scheduler"], [5, 0, 0, "-", "optimizer"]], "autograd.torch.optim.lr_scheduler": [[5, 2, 1, "", "LRScheduler"], [5, 2, 1, "", "LinearLR"]], "autograd.torch.optim.lr_scheduler.LRScheduler": [[5, 3, 1, "", "get_lr"], [5, 3, 1, "", "step"]], "autograd.torch.optim.lr_scheduler.LinearLR": [[5, 3, 1, "", "get_lr"]], "autograd.torch.optim.optimizer": [[5, 2, 1, "", "Optimizer"], [5, 2, 1, "", "SGD"]], "autograd.torch.optim.optimizer.Optimizer": [[5, 3, 1, "", "step"], [5, 3, 1, "", "zero_grad"]], "autograd.torch.optim.optimizer.SGD": [[5, 3, 1, "", "step"]], "autograd.torch.tensor": [[3, 2, 1, "", "Node"], [3, 2, 1, "", "Tensor"], [3, 2, 1, "", "no_grad"]], "autograd.torch.tensor.Tensor": [[3, 4, 1, "", "T"], [3, 3, 1, "", "accum_grad"], [3, 3, 1, "", "backward"], [3, 3, 1, "", "broadcast_axis"], [3, 3, 1, "", "exp"], [3, 5, 1, "", "grad_enabled"], [3, 3, 1, "", "log"], [3, 3, 1, "", "log_softmax"], [3, 3, 1, "", "relu"], [3, 3, 1, "", "sigmoid"], [3, 3, 1, "", "sum"], [3, 3, 1, "", "tanh"]], "test": [[10, 0, 0, "-", "autograd"], [10, 0, 0, "-", "test_engine"]], "test.autograd": [[10, 1, 1, "", "test_model"]], "test.test_engine": [[10, 1, 1, "", "test_more_ops"], [10, 1, 1, "", "test_sanity_check"]]}, "objtypes": {"0": "py:module", "1": "py:function", "2": "py:class", "3": "py:method", "4": "py:property", "5": "py:attribute"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "function", "Python function"], "2": ["py", "class", "Python class"], "3": ["py", "method", "Python method"], "4": ["py", "property", "Python property"], "5": ["py", "attribute", "Python attribute"]}, "titleterms": {"get": [0, 6], "start": [0, 6], "nano": [0, 6, 7, 8], "autograd": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10], "instal": [0, 6, 7], "usag": [0, 7], "mlp": 0, "multi": 0, "layer": 0, "perceptron": 0, "sparsemlp": 0, "linear": 0, "model": 0, "more": [0, 6], "exampl": [0, 6, 7], "packag": [1, 2, 3, 4, 5, 10], "subpackag": [1, 3], "modul": [1, 2, 3, 4, 5, 9, 10], "content": [1, 2, 3, 4, 5, 7, 10], "core": 2, "submodul": [2, 3, 4, 5, 10], "graph": 2, "spares_nn": 2, "engin": 2, "nn": [2, 4], "torch": [3, 4, 5], "init": 3, "tensor": 3, "function": 4, "optim": 5, "lr_schedul": 5, "faq": [6, 7], "q": 6, "what": 6, "i": 6, "ar": 6, "main": 6, "featur": 6, "how": 6, "do": 6, "can": 6, "us": 6, "other": 6, "librari": 6, "like": 6, "tensorflow": 6, "pytorch": 6, "ani": 6, "limit": 6, "known": 6, "issu": 6, "where": 6, "find": 6, "resourc": 6, "welcom": 7, "": 7, "document": 7, "introduct": 7, "tabl": 7, "api": 7, "refer": 7, "frequent": 7, "ask": 7, "question": 7, "indic": 7, "setup": 9, "test": 10, "test_engin": 10}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx": 57}, "alltitles": {"Get started": [[0, "get-started"]], "Nano-AutoGrad": [[0, "nano-autograd"], [8, "nano-autograd"]], "Installation": [[0, "installation"], [7, "installation"]], "Usage": [[0, "usage"], [7, "usage"]], "MLP (Multi-Layer Perceptron)": [[0, "mlp-multi-layer-perceptron"]], "SparseMLP": [[0, "sparsemlp"]], "Linear Model": [[0, "linear-model"]], "More Examples": [[0, "more-examples"]], "autograd package": [[1, "autograd-package"]], "Subpackages": [[1, "subpackages"], [3, "subpackages"]], "Module contents": [[1, "module-autograd"], [2, "module-autograd.core"], [3, "module-autograd.torch"], [4, "module-autograd.torch.nn"], [5, "module-autograd.torch.optim"], [10, "module-test"]], "autograd.core package": [[2, "autograd-core-package"]], "Submodules": [[2, "submodules"], [3, "submodules"], [4, "submodules"], [5, "submodules"], [10, "submodules"]], "autograd.core.Graph module": [[2, "module-autograd.core.Graph"]], "autograd.core.Spares_nn module": [[2, "module-autograd.core.Spares_nn"]], "autograd.core.engine module": [[2, "module-autograd.core.engine"]], "autograd.core.nn module": [[2, "module-autograd.core.nn"]], "autograd.torch package": [[3, "autograd-torch-package"]], "autograd.torch.init module": [[3, "module-autograd.torch.init"]], "autograd.torch.tensor module": [[3, "module-autograd.torch.tensor"]], "autograd.torch.nn package": [[4, "autograd-torch-nn-package"]], "autograd.torch.nn.functional module": [[4, "module-autograd.torch.nn.functional"]], "autograd.torch.nn.module module": [[4, "module-autograd.torch.nn.module"]], "autograd.torch.optim package": [[5, "autograd-torch-optim-package"]], "autograd.torch.optim.lr_scheduler module": [[5, "module-autograd.torch.optim.lr_scheduler"]], "autograd.torch.optim.optimizer module": [[5, "module-autograd.torch.optim.optimizer"]], "FAQ": [[6, "faq"]], "Q: What is Nano-AutoGrad?": [[6, "q-what-is-nano-autograd"]], "Q: What are the main features of Nano-AutoGrad?": [[6, "q-what-are-the-main-features-of-nano-autograd"]], "Q: How do I install Nano-AutoGrad?": [[6, "q-how-do-i-install-nano-autograd"]], "Q: How can I get started with Nano-AutoGrad?": [[6, "q-how-can-i-get-started-with-nano-autograd"]], "Q: Can I use Nano-AutoGrad with other libraries like TensorFlow or PyTorch?": [[6, "q-can-i-use-nano-autograd-with-other-libraries-like-tensorflow-or-pytorch"]], "Q: Are there any limitations or known issues with Nano-AutoGrad?": [[6, "q-are-there-any-limitations-or-known-issues-with-nano-autograd"]], "Q: Where can I find more examples and resources?": [[6, "q-where-can-i-find-more-examples-and-resources"]], "Welcome to Nano-AutoGrad's Documentation!": [[7, "welcome-to-nano-autograd-s-documentation"]], "Introduction": [[7, "introduction"]], "Contents": [[7, "contents"]], "Table of Contents": [[7, null]], "API Reference": [[7, "api-reference"]], "Examples": [[7, "examples"]], "FAQ (Frequently Asked Questions)": [[7, "faq-frequently-asked-questions"]], "Indices and Tables": [[7, "indices-and-tables"]], "setup module": [[9, "setup-module"]], "test package": [[10, "test-package"]], "test.autograd module": [[10, "module-test.autograd"]], "test.test_engine module": [[10, "module-test.test_engine"]]}, "indexentries": {"autograd": [[1, "module-autograd"]], "module": [[1, "module-autograd"], [2, "module-autograd.core"], [2, "module-autograd.core.Graph"], [2, "module-autograd.core.Spares_nn"], [2, "module-autograd.core.engine"], [2, "module-autograd.core.nn"], [3, "module-autograd.torch"], [3, "module-autograd.torch.init"], [3, "module-autograd.torch.tensor"], [4, "module-autograd.torch.nn"], [4, "module-autograd.torch.nn.functional"], [4, "module-autograd.torch.nn.module"], [5, "module-autograd.torch.optim"], [5, "module-autograd.torch.optim.lr_scheduler"], [5, "module-autograd.torch.optim.optimizer"], [10, "module-test"], [10, "module-test.autograd"], [10, "module-test.test_engine"]], "layer (class in autograd.core.nn)": [[2, "autograd.core.nn.Layer"]], "mlp (class in autograd.core.nn)": [[2, "autograd.core.nn.MLP"]], "module (class in autograd.core.spares_nn)": [[2, "autograd.core.Spares_nn.Module"]], "module (class in autograd.core.nn)": [[2, "autograd.core.nn.Module"]], "neuron (class in autograd.core.nn)": [[2, "autograd.core.nn.Neuron"]], "sparselayer (class in autograd.core.spares_nn)": [[2, "autograd.core.Spares_nn.SparseLayer"]], "sparsemlp (class in autograd.core.spares_nn)": [[2, "autograd.core.Spares_nn.SparseMLP"]], "sparseneuron (class in autograd.core.spares_nn)": [[2, "autograd.core.Spares_nn.SparseNeuron"]], "value (class in autograd.core.engine)": [[2, "autograd.core.engine.Value"]], "autograd.core": [[2, "module-autograd.core"]], "autograd.core.graph": [[2, "module-autograd.core.Graph"]], "autograd.core.spares_nn": [[2, "module-autograd.core.Spares_nn"]], "autograd.core.engine": [[2, "module-autograd.core.engine"]], "autograd.core.nn": [[2, "module-autograd.core.nn"]], "backward() (autograd.core.engine.value method)": [[2, "autograd.core.engine.Value.backward"]], "draw_dot() (in module autograd.core.graph)": [[2, "autograd.core.Graph.draw_dot"]], "parameters() (autograd.core.spares_nn.module method)": [[2, "autograd.core.Spares_nn.Module.parameters"]], "parameters() (autograd.core.spares_nn.sparselayer method)": [[2, "autograd.core.Spares_nn.SparseLayer.parameters"]], "parameters() (autograd.core.spares_nn.sparsemlp method)": [[2, "autograd.core.Spares_nn.SparseMLP.parameters"]], "parameters() (autograd.core.spares_nn.sparseneuron method)": [[2, "autograd.core.Spares_nn.SparseNeuron.parameters"]], "parameters() (autograd.core.nn.layer method)": [[2, "autograd.core.nn.Layer.parameters"]], "parameters() (autograd.core.nn.mlp method)": [[2, "autograd.core.nn.MLP.parameters"]], "parameters() (autograd.core.nn.module method)": [[2, "autograd.core.nn.Module.parameters"]], "parameters() (autograd.core.nn.neuron method)": [[2, "autograd.core.nn.Neuron.parameters"]], "relu() (autograd.core.engine.value method)": [[2, "autograd.core.engine.Value.relu"]], "softmax() (autograd.core.engine.value method)": [[2, "autograd.core.engine.Value.softmax"]], "trace() (in module autograd.core.graph)": [[2, "autograd.core.Graph.trace"]], "zero_grad() (autograd.core.spares_nn.module method)": [[2, "autograd.core.Spares_nn.Module.zero_grad"]], "zero_grad() (autograd.core.nn.module method)": [[2, "autograd.core.nn.Module.zero_grad"]], "node (class in autograd.torch.tensor)": [[3, "autograd.torch.tensor.Node"]], "t (autograd.torch.tensor.tensor property)": [[3, "autograd.torch.tensor.Tensor.T"]], "tensor (class in autograd.torch.tensor)": [[3, "autograd.torch.tensor.Tensor"]], "accum_grad() (autograd.torch.tensor.tensor method)": [[3, "autograd.torch.tensor.Tensor.accum_grad"]], "autograd.torch": [[3, "module-autograd.torch"]], "autograd.torch.init": [[3, "module-autograd.torch.init"]], "autograd.torch.tensor": [[3, "module-autograd.torch.tensor"]], "backward() (autograd.torch.tensor.tensor method)": [[3, "autograd.torch.tensor.Tensor.backward"]], "broadcast_axis() (autograd.torch.tensor.tensor static method)": [[3, "autograd.torch.tensor.Tensor.broadcast_axis"]], "exp() (autograd.torch.tensor.tensor method)": [[3, "autograd.torch.tensor.Tensor.exp"]], "grad_enabled (autograd.torch.tensor.tensor attribute)": [[3, "autograd.torch.tensor.Tensor.grad_enabled"]], "log() (autograd.torch.tensor.tensor method)": [[3, "autograd.torch.tensor.Tensor.log"]], "log_softmax() (autograd.torch.tensor.tensor method)": [[3, "autograd.torch.tensor.Tensor.log_softmax"]], "no_grad (class in autograd.torch.tensor)": [[3, "autograd.torch.tensor.no_grad"]], "relu() (autograd.torch.tensor.tensor method)": [[3, "autograd.torch.tensor.Tensor.relu"]], "sigmoid() (autograd.torch.tensor.tensor method)": [[3, "autograd.torch.tensor.Tensor.sigmoid"]], "sum() (autograd.torch.tensor.tensor method)": [[3, "autograd.torch.tensor.Tensor.sum"]], "tanh() (autograd.torch.tensor.tensor method)": [[3, "autograd.torch.tensor.Tensor.tanh"]], "linear (class in autograd.torch.nn.module)": [[4, "autograd.torch.nn.module.Linear"]], "module (class in autograd.torch.nn.module)": [[4, "autograd.torch.nn.module.Module"]], "autograd.torch.nn": [[4, "module-autograd.torch.nn"]], "autograd.torch.nn.functional": [[4, "module-autograd.torch.nn.functional"]], "autograd.torch.nn.module": [[4, "module-autograd.torch.nn.module"]], "binary_cross_entropy() (in module autograd.torch.nn.functional)": [[4, "autograd.torch.nn.functional.binary_cross_entropy"]], "exp() (in module autograd.torch.nn.functional)": [[4, "autograd.torch.nn.functional.exp"]], "forward() (autograd.torch.nn.module.linear method)": [[4, "autograd.torch.nn.module.Linear.forward"]], "forward() (autograd.torch.nn.module.module method)": [[4, "autograd.torch.nn.module.Module.forward"]], "huber_loss() (in module autograd.torch.nn.functional)": [[4, "autograd.torch.nn.functional.huber_loss"]], "log() (in module autograd.torch.nn.functional)": [[4, "autograd.torch.nn.functional.log"]], "log_softmax() (in module autograd.torch.nn.functional)": [[4, "autograd.torch.nn.functional.log_softmax"]], "modules() (autograd.torch.nn.module.module method)": [[4, "autograd.torch.nn.module.Module.modules"]], "mse_loss() (in module autograd.torch.nn.functional)": [[4, "autograd.torch.nn.functional.mse_loss"]], "nll_loss() (in module autograd.torch.nn.functional)": [[4, "autograd.torch.nn.functional.nll_loss"]], "parameters() (autograd.torch.nn.module.module method)": [[4, "autograd.torch.nn.module.Module.parameters"]], "relu() (in module autograd.torch.nn.functional)": [[4, "autograd.torch.nn.functional.relu"]], "sigmoid() (in module autograd.torch.nn.functional)": [[4, "autograd.torch.nn.functional.sigmoid"]], "tanh() (in module autograd.torch.nn.functional)": [[4, "autograd.torch.nn.functional.tanh"]], "lrscheduler (class in autograd.torch.optim.lr_scheduler)": [[5, "autograd.torch.optim.lr_scheduler.LRScheduler"]], "linearlr (class in autograd.torch.optim.lr_scheduler)": [[5, "autograd.torch.optim.lr_scheduler.LinearLR"]], "optimizer (class in autograd.torch.optim.optimizer)": [[5, "autograd.torch.optim.optimizer.Optimizer"]], "sgd (class in autograd.torch.optim.optimizer)": [[5, "autograd.torch.optim.optimizer.SGD"]], "autograd.torch.optim": [[5, "module-autograd.torch.optim"]], "autograd.torch.optim.lr_scheduler": [[5, "module-autograd.torch.optim.lr_scheduler"]], "autograd.torch.optim.optimizer": [[5, "module-autograd.torch.optim.optimizer"]], "get_lr() (autograd.torch.optim.lr_scheduler.lrscheduler method)": [[5, "autograd.torch.optim.lr_scheduler.LRScheduler.get_lr"]], "get_lr() (autograd.torch.optim.lr_scheduler.linearlr method)": [[5, "autograd.torch.optim.lr_scheduler.LinearLR.get_lr"]], "step() (autograd.torch.optim.lr_scheduler.lrscheduler method)": [[5, "autograd.torch.optim.lr_scheduler.LRScheduler.step"]], "step() (autograd.torch.optim.optimizer.optimizer method)": [[5, "autograd.torch.optim.optimizer.Optimizer.step"]], "step() (autograd.torch.optim.optimizer.sgd method)": [[5, "autograd.torch.optim.optimizer.SGD.step"]], "zero_grad() (autograd.torch.optim.optimizer.optimizer method)": [[5, "autograd.torch.optim.optimizer.Optimizer.zero_grad"]], "test": [[10, "module-test"]], "test.autograd": [[10, "module-test.autograd"]], "test.test_engine": [[10, "module-test.test_engine"]], "test_model() (in module test.autograd)": [[10, "test.autograd.test_model"]], "test_more_ops() (in module test.test_engine)": [[10, "test.test_engine.test_more_ops"]], "test_sanity_check() (in module test.test_engine)": [[10, "test.test_engine.test_sanity_check"]]}})